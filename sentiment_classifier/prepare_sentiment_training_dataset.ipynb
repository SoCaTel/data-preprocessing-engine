{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../src/scorers'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import utils # import pre_process_free_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload  # Python 3.4+ only.\n",
    "\n",
    "utils = reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIMUM_WORD_COUNT = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment towards products' file conversion\n",
    "This file has been selected as group conversations are usually geared towards judging existing services and commenting about newly proposed services. Give this, it is clear that this resembles sentiment towards products/brands, which the following dataset captures.\n",
    "\n",
    "To complement this dataset, we also use the movie sentiment dataset already available, but only use the very positive/negative comments made to remove noise from more neutral comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_json_struct = {\n",
    "    \"eventTime\": \"2015-06-08T16:58:14.285+0000\",\n",
    "    \"entityId\": 73168,\n",
    "    \"entityType\": \"source\",\n",
    "    \"properties\": {\n",
    "        \"phrase\": \"real transformation\",\n",
    "        \"sentiment\": 2\n",
    "    },\n",
    "    \"event\": \"phrases\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('judge-1377884607_tweet_product_company.csv'):    \n",
    "    # \"https://www.crowdflower.com/wp-content/uploads/2016/03/judge-1377884607_tweet_product_company.csv\" -- Removed\n",
    "    r = requests.get(\"https://query.data.world/s/5gxidpupmkcesf43vkltv4h6s7erlv\")\n",
    "    open('judge-1377884607_tweet_product_company.csv', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dataset_1 = pd.read_csv(\"judge-1377884607_tweet_product_company.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5389\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dataset_1.is_there_an_emotion_directed_at_a_brand_or_product.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter for rows that have a sentiment recognised at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dataset_1_f = sent_dataset_1[sent_dataset_1['is_there_an_emotion_directed_at_a_brand_or_product'].isin(['Positive emotion', 'Negative emotion'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dataset_1_f['num_sentiment'] = 0\n",
    "\n",
    "sent_dataset_1_f.loc[sent_dataset_1_f['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Positive emotion', 'num_sentiment'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2978\n",
       "0     570\n",
       "Name: num_sentiment, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dataset_1_f['num_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3548\n"
     ]
    }
   ],
   "source": [
    "entity_counter = 0\n",
    "\n",
    "def process_text(entry, f_json):\n",
    "    global entity_counter\n",
    "    if entry['tweet_text'] is not np.nan:\n",
    "        try:\n",
    "            clean_text_l = utils.pre_process_free_text(entry['tweet_text'], lang_id=1, rm_stopwords=False)\n",
    "            \n",
    "            if len(clean_text_l) >= MINIMUM_WORD_COUNT:\n",
    "                clean_text = ' '.join(clean_text_l)\n",
    "                clean_text = clean_text.replace(\"'\", \"\")\n",
    "\n",
    "                json_struct = {\n",
    "                    \"entityId\": entity_counter,\n",
    "                    \"entityType\": \"source\",\n",
    "                    \"properties\": {\n",
    "                        \"phrase\": clean_text,\n",
    "                        \"sentiment\": entry['num_sentiment']\n",
    "                    },\n",
    "                    \"event\": \"phrases\"\n",
    "                }\n",
    "                \n",
    "                entity_counter += 1\n",
    "\n",
    "                f_json.write(json.dumps(json_struct) + \"\\n\")\n",
    "                return clean_text\n",
    "            else:\n",
    "                return None\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            return None\n",
    "\n",
    "f = open('product_sentiment.json', 'w')\n",
    "sent_dataset_1_f['clean_tweet_text'] = sent_dataset_1_f.apply(process_text, axis=1, f_json=f)\n",
    "print(entity_counter)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a JSON file in the format that PIO will accept it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_properties_column(row):\n",
    "    return {\"phrase\": row['clean_tweet_text'], \"sentiment\": row['num_sentiment']}\n",
    "\n",
    "sent_dataset_1_f['entityId'] = sent_dataset_1_f.index\n",
    "sent_dataset_1_f['entityType'] = \"source\"\n",
    "sent_dataset_1_f['properties'] = sent_dataset_1_f.apply(prepare_properties_column, axis=1)\n",
    "sent_dataset_1_f['event'] = \"phrases\"\n",
    "\n",
    "sent_dataset_1_json = sent_dataset_1_f[['entityId', 'entityType', 'properties', 'event']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dataset_1_f.to_json(\"final_sentiment.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default sentiment file to 0 - 1 scale\n",
    "For this part, we will need the file included by default in the text classification template under the name `template/sentimentanalysis.json`. Retrieve this and place it in the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_f = open('sentimentanalysis.json', 'r')\n",
    "new_default = open('clean_default_sentiment_analysis.json', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_map = {0: 0, 1: 0, 2: 0, 3: 1, 4: 1}\n",
    "sentiment_map = {0: 0, 4: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = set()\n",
    "\n",
    "for line in default_f.readlines():\n",
    "    line_json = json.loads(line)\n",
    "    sent = line_json['properties']['sentiment']\n",
    "    if sent in list(sentiment_map.keys()):\n",
    "        new_sent = sentiment_map[sent]  # Re-map to a 0 - 1 scale.\n",
    "        line_json['properties']['sentiment'] = new_sent\n",
    "\n",
    "        line_json['properties']['phrase'] = line_json['properties']['phrase'].replace(\"'\", \"\")  # .lower()\n",
    "        words = line_json['properties']['phrase'].split(\" \")\n",
    "        unique_words.update(words)\n",
    "        if len(words) >= MINIMUM_WORD_COUNT:\n",
    "            # re-organise entityIds\n",
    "            del line_json['eventTime']\n",
    "            line_json['entityId'] = entity_counter  # Continue from where we left off.\n",
    "            entity_counter += 1\n",
    "\n",
    "            new_default.write(json.dumps(line_json) + '\\n')\n",
    "\n",
    "default_f.close()\n",
    "new_default.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3445"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    output = subprocess.check_output(\n",
    "        ['bash','-c', \n",
    "         \"cat 'clean_default_sentiment_analysis.json' >> 'clean_default_sentiment_analysis.json'\"])\n",
    "except subprocess.CalledProcessError as e:\n",
    "    raise RuntimeError(\"command '{}' return with error (code {}): {}\".format(e.cmd, e.returncode, e.output))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
